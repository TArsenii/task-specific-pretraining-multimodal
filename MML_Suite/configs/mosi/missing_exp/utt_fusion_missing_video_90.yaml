!StandardConfig
experiment: !ExperimentConfig
  name: "UTT_FUSION MOSI Pretrained Encoders Missing Video 90%"
  device: "cuda"
  train_print_interval_epochs: 1
  validation_print_interval_epochs: 1
  is_train: true
  is_test: true

model: !ModelConfig
  name: "UTT-Fusion"
  model_type: "UttFusionModel"
  
  # Paths to pretrained encoders
  pretrained_encoders:
    audio: "experiments_output/MOSI_Audio_Encoder_Pretrain/models/1/encoder_audio_best.pth"
    video: "experiments_output/MOSI_Video_Encoder_Pretrain/models/1/encoder_video_best.pth"
    text: "experiments_output/MOSI_Text_Encoder_Pretrain/models/1/encoder_text_best.pth"
  
  # Encoders with the same configuration as in pretraining
  netA: !LSTMEncoder
    input_size: 5
    hidden_size: 64
    embd_method: "last"

  netV: !LSTMEncoder
    input_size: 20
    hidden_size: 64
    embd_method: "last"

  netT: !TextCNN
    input_size: 768
    embd_size: 64
    dropout: 0.5
    in_channels: 1
    out_channels: 128
    kernel_heights: 
      - 3
      - 4
      - 5

  netC: !FcClassifier
    input_dim: 192
    layers: 
      - 192
      - 64
      - 32
    output_dim: 3
    dropout: 0.5

  clip: 1.0

training:
  epochs: 100
  early_stopping: true
  early_stopping_patience: 10
  num_modalities: 3
  
  # Using single optimizer for all parameters
  optimizer: !Optimizer
    name: "Adam"
    default_kwargs:
      lr: !!float 5e-5
      weight_decay: 0.001
  
  # Adding encoder_optimizer for compatibility with code
  encoder_optimizer: !Optimizer
    name: "Adam"
    default_kwargs:
      lr: !!float 1e-5
      weight_decay: 0.001
  
  loss_functions: !LossFunctionGroup
    cross_entropy: 
      loss_name: "cross_entropy"
      loss_args: {}
      weight: 1.0

data: !DataConfig
  datasets:
    train: !DatasetConfig
      dataset: "MOSI"
      data_fp: "$EXP_PATH/DATA/mosi/aligned_50.pkl"
      split: "train"
      target_modality: !Modality "MULTIMODAL"
      shuffle: true
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality AUDIO: !ModalityConfig
            missing_rate: 0.0  # Audio is always present
          !Modality VIDEO: !ModalityConfig
            missing_rate: 0.9  # Video is missing in 90% of cases
          !Modality TEXT: !ModalityConfig 
            missing_rate: 0.0  # Text is always present
        selected_patterns: ["atv", "at"]  # Using combinations atv and at (when video is missing)
      kwargs:
        labels_key: "classification_labels"
        aligned: true
    validation: !DatasetConfig
      dataset: "MOSI"
      data_fp: "$EXP_PATH/DATA/mosi/aligned_50.pkl"
      split: "valid"
      shuffle: true

      target_modality: !Modality "MULTIMODAL"
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality AUDIO: !ModalityConfig
            missing_rate: 0.0  # Audio is always present
          !Modality VIDEO: !ModalityConfig
            missing_rate: 0.9  # Video is missing in 90% of cases
          !Modality TEXT: !ModalityConfig 
            missing_rate: 0.0  # Text is always present
        selected_patterns: ["atv", "a", "v", "t", "av", "at", "tv"]
      kwargs:
        aligned: true
        labels_key: "classification_labels"

    test: !DatasetConfig
      dataset: "MOSI"
      data_fp: "$EXP_PATH/DATA/mosi/aligned_50.pkl"
      split: "test"
      target_modality: !Modality "MULTIMODAL"
      shuffle: true
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality AUDIO: !ModalityConfig
            missing_rate: 0.0  # Audio is always present
          !Modality VIDEO: !ModalityConfig
            missing_rate: 0.9  # Video is missing in 90% of cases
          !Modality TEXT: !ModalityConfig 
            missing_rate: 0.0  # Text is always present
        selected_patterns: ["atv", "a", "v", "t", "av", "at", "tv"]
      kwargs:
        aligned: true
        labels_key: "classification_labels"

    embeddings: !DatasetConfig
      dataset: "MOSI"
      data_fp: "$EXP_PATH/DATA/mosi/aligned_50.pkl"
      split: "test"
      target_modality: !Modality "MULTIMODAL"
      shuffle: true
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality AUDIO: !ModalityConfig
            missing_rate: 0.0  # Using all modalities for embeddings
          !Modality VIDEO: !ModalityConfig
            missing_rate: 0.0
          !Modality TEXT: !ModalityConfig 
            missing_rate: 0.0
        selected_patterns: ["atv"]
      kwargs:
        aligned: true
        labels_key: "classification_labels"

metrics:
  metrics:
    MSA:
      function: "metrics.msa_binary_classification"
      kwargs: {}
      level: "epoch"
    ConfusionMatrix:
      function: "sklearn.metrics.confusion_matrix"
      kwargs: 
        labels: [0, 1, 2]
      level: "epoch"
  groups:
    classification: ["MSA", "ConfusionMatrix"]
logging:
  log_path: "$EXP_PATH/experiments_output/{experiment_name}/logs/{run_id}"
  model_output_path: "$EXP_PATH/experiments_output/{experiment_name}/models/{run_id}"
  metrics_path: "$EXP_PATH/experiments_output/{experiment_name}/metrics/{run_id}"
  save_metric: "loss"
  monitor_path: "$EXP_PATH/experiments_output/{experiment_name}/monitoring/{run_id}"
  tensorboard_path: "$EXP_PATH/experiments_output/{experiment_name}/tensorboard/{run_id}"
  tb_record_only:
    - "loss"

monitoring:
  enabled: false
  gradient_interval: 100
  activation_interval: 100
  weight_interval: 200
  buffer_size: 1000
  compression: "gzip"
  compression_opts: 4
  enable_gradient_tracking: true
  enable_activation_tracking: true
  enable_weight_tracking: true
  enable_layer_convergence: true
  enable_information_flow: false