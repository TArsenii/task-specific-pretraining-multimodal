## Part of Chapter 3 experiments.
## Configuration file for training the MMIN model with:
## - Pretrained UttFusion model on MOSEI with the best model from the base model training
## - Same data configuration as the UttFusion model
## - Modalities are either present or not present in the pattern, 0% or 100% missing
!StandardConfig
experiment: !ExperimentConfig
  name: "REDCORE MODEL Missing 90"
  device: "cuda"
  train_print_interval_epochs: 1
  validation_print_interval_epochs: 1
  is_train: true
  is_test: true

model: !ModelConfig
  name: "RedCore"
  model_type: "RedCore"
  init_fn: "kaiming" ## TODO DOUBLE CHECK THIS
  
  netA: !Transformer
    width: 74
    layers: 3
    heads: 8
    embd_width: 96
  netV: !Transformer
    width: 35
    layers: 3
    heads: 8
    embd_width: 96
  netT: !Transformer
    width: 768
    layers: 3
    heads: 8
    embd_width: 96
  netAE: !ResidualAE
    layers: 
      - 160
      - 80
      - 32
    n_blocks: 5
    input_dim: 288
    dropout: 0.0
    use_bn: false
  netAV_T: !ResidualXE
    layers: 
      - 160
      - 80
      - 32
    n_blocks: 5
    input_dim: 192
    output_dim: 96
    dropout: 0.0
    use_bn: false
  netAT_V: !ResidualXE
    layers: 
      - 160
      - 80
      - 32
    n_blocks: 5
    input_dim: 192
    output_dim: 96
    dropout: 0.0
    use_bn: false
  netVT_A: !ResidualXE
    layers: 
      - 160
      - 80
      - 32
    n_blocks: 5
    input_dim: 192
    output_dim: 96
    dropout: 0.0
    use_bn: false
  netC: !FcClassifier
    input_dim: 288
    layers: 
      - 96
      - 96
    output_dim: 3
    dropout: 0.5
    use_bn: true
  netC_A: !FcClassifier
    input_dim: 96
    layers: 
      - 96
      - 96
    output_dim: 3
    dropout: 0.5
    use_bn: true
  netC_V: !FcClassifier
    input_dim: 96
    layers: 
      - 96
      - 96
    output_dim: 3
    dropout: 0.5
    use_bn: true
  netC_T: !FcClassifier
    input_dim: 96
    layers: 
      - 96
      - 96
    output_dim: 3
    dropout: 0.5
    use_bn: true
  clip: 1.0

training:
  epochs: 30
  batch_size: 256 
  early_stopping: false
  early_stopping_patience: 15
  early_stopping_metric: "loss"
  num_modalities: 3
  optimizer: !Optimizer
    name: "Adam"
    default_kwargs:
      lr: 2e-4
      weight_decay: 0.00001
      betas: [0.9, 0.999]
  loss_functions: !LossFunctionGroup
    cross_entropy: 
      loss_name: "cross_entropy"
      loss_args: {}
      weight: 1.0
    mse: 
      loss_name: "mse"
      loss_args: 
        reduction: "sum"
      weight: 4.0
  scheduler: "cosine"
  scheduler_args:
    T_max: 30

data: !DataConfig
  datasets:
    train: !DatasetConfig
      dataset: "mosei"
      data_fp: "$EXP_PATH/DATA/mosei/aligned.pkl"
      split: "train"
      target_modality: !Modality "MULTIMODAL"
      shuffle: true
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality audio: !ModalityConfig
            missing_rate: 0.9 
          !Modality video: !ModalityConfig
            missing_rate: 0.9
          !Modality text: !ModalityConfig 
            missing_rate: 0.9
        selected_patterns: ["avt", "a", "v", "t", "av", "at", "vt"] ## one of these will be selected randomly for each item during training
      kwargs:
        labels_key: "classification_labels"
        aligned: true
    validation: !DatasetConfig
      dataset: "mosei"
      data_fp: "$EXP_PATH/DATA/mosei/aligned.pkl"
      split: "valid"
      shuffle: true
      target_modality: !Modality "MULTIMODAL"
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality audio: !ModalityConfig
            missing_rate: 0.0  
          !Modality video: !ModalityConfig
            missing_rate: 0.0  
          !Modality text: !ModalityConfig 
            missing_rate: 0.0  
        selected_patterns: ["avt", "a", "v", "t", "av", "at", "vt"]
      kwargs:
        aligned: true
        labels_key: "classification_labels"

    test: !DatasetConfig
      dataset: "mosei"
      data_fp: "$EXP_PATH/DATA/mosei/aligned.pkl"
      split: "test"
      target_modality: !Modality "MULTIMODAL"
      shuffle: true
      missing_patterns: !MissingPatternConfig
        modalities:
          !Modality audio: !ModalityConfig
            missing_rate: 0.0  
          !Modality video: !ModalityConfig
            missing_rate: 0.0  
          !Modality text: !ModalityConfig 
            missing_rate: 0.0  
        selected_patterns: ["avt", "a", "v", "t", "av", "at", "vt"]
      kwargs:
        aligned: true
        labels_key: "classification_labels"


metrics:
  metrics:
    Accuracy:
      function: "sklearn.metrics.accuracy_score"
      kwargs: {}
      level: "epoch"
    F1_Weighted:
      function: "sklearn.metrics.f1_score"
      kwargs: 
        average: "weighted"
        zero_division: 0
      level: "epoch"    
    F1_Micro:
      function: "sklearn.metrics.f1_score"
      kwargs: 
        average: "micro"
        zero_division: 0
      level: "epoch"
    F1_Macro:
      function: "sklearn.metrics.f1_score"
      kwargs:
        average: "macro"
        zero_division: 0
      level: "epoch"
    Precision_Weighted:
      function: "sklearn.metrics.precision_score"
      kwargs: 
        average: "weighted"
        zero_division: 0
      level: "epoch"
    Precision_Micro:
      function: "sklearn.metrics.precision_score"
      kwargs:
        average: "micro"
        zero_division: 0
      
      level: "epoch"
    Precision_Macro:
      function: "sklearn.metrics.precision_score"
      kwargs:
        average: "macro"
        zero_division: 0
      level: "epoch"
    Recall_Weighted:
      function: "sklearn.metrics.recall_score"
      kwargs: 
        average: "weighted"
        zero_division: 0
      level: "epoch"
    Recall_Micro:
      function: "sklearn.metrics.recall_score"
      kwargs: 
        average: "micro"
        zero_division: 0
      level: "epoch"
    Recall_Macro:
      function: "sklearn.metrics.recall_score"
      kwargs: 
        average: "macro"
        zero_division: 0
      level: "epoch"
    MSA:
      function: "metrics.msa_binary_classification"
      kwargs: {}
      level: "epoch"
    ConfusionMatrix:
      function: "metrics.confusion_matrix_from_logits"
      kwargs: {
        "labels": [0, 1, 2]
      }
      level: "epoch"

logging:
  log_path: "$EXP_PATH/experiments_output/{experiment_name}/logs/{run_id}"
  model_output_path: "$EXP_PATH/experiments_output/{experiment_name}/models/{run_id}"
  metrics_path: "$EXP_PATH/experiments_output/{experiment_name}/metrics/{run_id}"
  save_metric: "Recall_Macro_ATV"
  monitor_path: "$EXP_PATH/experiments_output/{experiment_name}/monitoring/{run_id}"
  tensorboard_path: "$EXP_PATH/experiments_output/{experiment_name}/tensorboard/{run_id}"
  tb_record_only:
    - "loss"

monitoring:
  enabled: false
  gradient_interval: 100
  activation_interval: 100
  weight_interval: 200
  buffer_size: 1000
  compression: "gzip"
  compression_opts: 4
  enable_gradient_tracking: true
  enable_activation_tracking: true
  enable_weight_tracking: true
  enable_layer_convergence: true
  enable_information_flow: false